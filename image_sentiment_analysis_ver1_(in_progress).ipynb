{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image sentimental analysis_ver1 (in progress).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nttUXJ5-8GBu"
      },
      "source": [
        "from tensorflow import keras\n",
        "import os, shutil"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wve_qe2oQu-U",
        "outputId": "22ee1afb-d446-499b-d27d-1a50b9e54aad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AOJddjQPIgB"
      },
      "source": [
        "이미지 파일 load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tdUe6aPwUHy"
      },
      "source": [
        "train_dir = '/content/drive/MyDrive/images_crawling/train'\n",
        "test_dir='/content/drive/MyDrive/images_crawling/validation'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8nc6VIrcqau"
      },
      "source": [
        "데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ieYbVJhtX8"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST913kgbhxge"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255.)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heYcc5tcgYAW"
      },
      "source": [
        "Data Augmentation 정보 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AjVlr3_MISA"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                            rescale=1./255.,\n",
        "                            rotation_range=40,\n",
        "                             width_shift_range=0.2,\n",
        "                             height_shift_range=0.2,\n",
        "                             shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                            rescale=1./255.,\n",
        "                          )\n",
        "validation_datagen = ImageDataGenerator(\n",
        "                            rescale=1./255.,\n",
        "                          )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97reh_oxPe2U"
      },
      "source": [
        "DirectoryIterator 객체 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmHqia-NBDue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6450a18-f5fc-4a26-d991-cf7c274d58c1"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 20,\n",
        "    shuffle = True,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 20,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 20,\n",
        "    class_mode = 'categorical',\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 300 images belonging to 3 classes.\n",
            "Found 0 images belonging to 3 classes.\n",
            "Found 300 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xE1fshxPlpX"
      },
      "source": [
        "CNN 모델 디자인 및 학습 정보 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2c9fqg9u6wU"
      },
      "source": [
        "from tensorflow.keras import models, layers, utils"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6IdqQtWL1dM"
      },
      "source": [
        "model = models.Sequential([])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNMy8YvnkvFZ"
      },
      "source": [
        "\n",
        "model.add(layers.Conv2D(filters=32, \n",
        "                        kernel_size=3, \n",
        "                        activation='relu',\n",
        "                        input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(filters=64, \n",
        "                        kernel_size=3, \n",
        "                        activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(filters=128, \n",
        "                        kernel_size=3, \n",
        "                        activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(filters=128, \n",
        "                        kernel_size=3, \n",
        "                        activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlSXcAF2k2Vk"
      },
      "source": [
        "model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdpYcivWP9UB"
      },
      "source": [
        "데이터 연결 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN_cR_vEvIZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe227b58-3db7-41f2-a25d-0d6fa3087e56"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "          epochs=10,\n",
        "          steps_per_epoch=len(train_generator),\n",
        "          validation_data = validation_generator,\n",
        "          validation_steps = len(validation_generator))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 5s 178ms/step - loss: 1.3001 - accuracy: 0.4033\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 3s 186ms/step - loss: 0.7684 - accuracy: 0.5800\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 3s 184ms/step - loss: 0.7565 - accuracy: 0.6400\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 3s 188ms/step - loss: 0.6436 - accuracy: 0.6833\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 3s 186ms/step - loss: 0.6050 - accuracy: 0.7100\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 3s 187ms/step - loss: 0.5803 - accuracy: 0.7233\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 3s 186ms/step - loss: 0.5335 - accuracy: 0.7700\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 3s 186ms/step - loss: 0.5596 - accuracy: 0.6933\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 3s 187ms/step - loss: 0.6233 - accuracy: 0.6967\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 3s 185ms/step - loss: 0.4740 - accuracy: 0.7733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JZMraFxfcyM",
        "outputId": "9bb60071-8e28-4ade-f797-50a94536415e"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('saved_model/image_sentimental_analysis')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/image_sentimental_analysis/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYQnScauRf2l"
      },
      "source": [
        "test 데이터셋으로 모델 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_-k2D0knKaC"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
